# Awesome Transformer in Vision [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)  
A curated list of vision transformer related resources. Please feel free to [pull requests](https://github.com/penghouwen/VisionTransformer/pulls) or [open an issue](https://github.com/penghouwen/VisionTransformer/issues) to add papers.


## Table of Contents

- [Awesome Surveys](#awesome-surveys)

- [Transformer in Vision](#transformer-in-vision)
  - [2021 Venues](#2021)
  - [2020 Venues](#2020)
  - [2019 Venues](#2019)
  - [Previous Venues](#2012-2018)
  
  - [Awesome Libraies](#awesome-surveys)

## Awesome Surveys

|  Title  |   Venue  |   BibTeX  |
|:--------|:--------:|:--------:|
| [A Survey on Visual Transformer](https://arxiv.org/pdf/2012.12556.pdf) | ArXiv | [Bib](https://scholar.googleusercontent.com/scholar.bib?q=info:Aj10Crv7DScJ:scholar.google.com/&output=citation&scisdr=CgUmooQTEM3KnAOogfQ:AAGBfm0AAAAAX_-tmfT1yhaAeO62lS61HGcSpcXSUqJ5&scisig=AAGBfm0AAAAAX_-tmQAIcm-VKBRqnb9iTs8Sghq-6ssB&scisf=4&ct=citation&cd=-1&hl=ja)

## Transformer in Vision

|      Task   |        Reg       |       Det    |           Seg           |        Trk           |    Other   |
|:------------|:--------------:|:----------------------:|:-----------------------:|:----------------------:|:----------:|
| Explanation | Image Recoginition | Object Detection | Image Segmentation | Object Tracking | other types |

You can add a tag for `domains` which contains several transformer-based works

### 2021
(Pls follow Time Inverse Ranking)

|  Title  |   Venue  |  Task  |   Code   |  BibTeX  |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [TrackFormer: Multi-Object Tracking with Transformers](https://arxiv.org/abs/2101.02702) | Arxiv | Trk | [GitHub]() | [Bib](https://scholar.googleusercontent.com/scholar.bib?q=info:FPvKVRbtrIsJ:scholar.google.com/&output=citation&scisdr=CgUmooVjENWd0wS0GSo:AAGBfm0AAAAAX_-xASqzkmKVlI_ghtAFBTJPBLDUYfFD&scisig=AAGBfm0AAAAAX_-xAQWgW5KYRtnhpPb41ke6jWK4XpsF&scisf=4&ct=citation&cd=-1&hl=zh-CN)


### 2020

|  Title  |   Venue  |  Task  |   Code   |  BibTeX  |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877) | ArXiv | Reg | [GitHub](https://github.com/facebookresearch/deit) | [Bib](https://scholar.googleusercontent.com/scholar.bib?q=info:4M9RfcZARQAJ:scholar.google.com/&output=citation&scisdr=CgUmooQTEM3KnAOiWXQ:AAGBfm0AAAAAX_-nQXQ83NjCdo7Z_4UWZCvWuv3z-goK&scisig=AAGBfm0AAAAAX_-nQbm3aZWNrAaIc6-RB8eIGfbbMANa&scisf=4&ct=citation&cd=-1&hl=ja)
| [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) | ICLR | Reg | [GitHub](https://github.com/google-research/vision_transformer) | [Bib](https://scholar.googleusercontent.com/scholar.bib?q=info:K33r8boRRloJ:scholar.google.com/&output=citation&scisdr=CgUmooQTEM3KnAOgs5I:AAGBfm0AAAAAX_-lq5IwW1PWPCcrPyJSzxHG4hXCLpmx&scisig=AAGBfm0AAAAAX_-lq2wYJkeX630SaKwHHcWBaOT4DHMa&scisf=4&ct=citation&cd=-1&hl=ja)
| [ Toward Transformer-Based Object Detection](https://arxiv.org/abs/2012.09958) | ArXiv | Det | [ ---]( ---) | [Bib]( https://scholar.googleusercontent.com/scholar.bib?q=info:HNio9f4uZ3MJ:scholar.google.com/&output=citation&scisdr=CgXVb0CVEIDLq_pQxe0:AAGBfm0AAAAAYAFV3e2X4w2PvtWlBqJv6hXxAg6wZ03V&scisig=AAGBfm0AAAAAYAFV3Yb8S4l3zocHB5pRYbTR-27niTuk&scisf=4&ct=citation&cd=-1&hl=ja)
| [ Rethinking Transformer-based Set Prediction for Object Detection](https://arxiv.org/abs/2011.10881) | ArXiv | Det | [ ---]( ---) | [Bib]( https://scholar.googleusercontent.com/scholar.bib?q=info:Hqq-vvg01HIJ:scholar.google.com/&output=citation&scisdr=CgWnIAGoEIDLq_pTftc:AAGBfm0AAAAAYAFWZtc9tMFRODX6KXerZKv6C3jGhUND&scisig=AAGBfm0AAAAAYAFWZjJyD-RVGr4WrxoTLdE-31QG_mbc&scisf=4&ct=citation&cd=-1&hl=ja)
| [ UP-DETR: Unsupervised Pre-training for Object Detection with Transformers](https://arxiv.org/abs/2011.09094) | ArXiv | Det | [ ---]( ---) | [Bib]( https://scholar.googleusercontent.com/scholar.bib?q=info:fKaDo0dq4ZQJ:scholar.google.com/&output=citation&scisdr=CgWnIAGoEIDLq_pSHIY:AAGBfm0AAAAAYAFXBIZ_wVD78VGiYjEbSztYdjCH6gAj&scisig=AAGBfm0AAAAAYAFXBCkannnFghByYVFUnKWIycAdbppk&scisf=4&ct=citation&cd=-1&hl=ja)
| [ Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159) | ArXiv | Det | [ GitHub]( https://github.com/fundamentalvision/Deformable-DETR) | [Bib]( https://scholar.googleusercontent.com/scholar.bib?q=info:fKaDo0dq4ZQJ:scholar.google.com/&output=citation&scisdr=CgWnIAGoEIDLq_pSHIY:AAGBfm0AAAAAYAFXBIZ_wVD78VGiYjEbSztYdjCH6gAj&scisig=AAGBfm0AAAAAYAFXBCkannnFghByYVFUnKWIycAdbppk&scisf=4&ct=citation&cd=-1&hl=ja)
| [ End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) | ECCV | Det | [ GitHub]( https://github.com/facebookresearch/detr) | [Bib]( https://citation-needed.springer.com/v2/references/10.1007/978-3-030-58452-8_13?format=bibtex&flavour=citation)
| [ MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers](https://arxiv.org/abs/2012.00759) | --- | Seg | [ ---]( ---) | <details> <summary>Bib</summary> <p align="left">  @article{wang2020max, </br>
  title={MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers}, </br>
  author={Wang, Huiyu and Zhu, Yukun and Adam, Hartwig and Yuille, Alan and Chen, Liang-Chieh}, </br>
  journal={arXiv preprint arXiv:2012.00759}, </br>
  year={2020}
}  </p></details>  



| [ ---](https://arxiv.org/abs/2010.11929) | --- | Seg | [ ---]( ---) | [Bib]( ---)
| [TransTrack: Multiple-Object Tracking with Transformer](https://arxiv.org/abs/2012.15460) | ArXiv | Trk | [GitHub](https://github.com/PeizeSun/TransTrack) | [Bib](https://scholar.googleusercontent.com/scholar.bib?q=info:QzpLQuJ5l44J:scholar.google.com/&output=citation&scisdr=CgUmooRjENWd0wS1QH4:AAGBfm0AAAAAX_-wWH4lrREtg2mlyHhTdsKrRwTMe_wY&scisig=AAGBfm0AAAAAX_-wWDKIgsxWD2AY6ASlNXLdgqhJmhXL&scisf=4&ct=citation&cd=-1&hl=zh-CN)


### 2019

|  Title  |   Venue  |  Task  |   Code   |  BibTeX  |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [Training data-efficient image transformers & distillation through attention](https://arxiv.org/abs/2012.12877) | ArXiv | Reg | [GitHub](https://github.com/facebookresearch/deit) | -
| [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) | ICLR | Reg | [GitHub](https://github.com/google-research/vision_transformer) | -

### 2012-2018

|  Title  |   Venue  |  Task  |   Code   |  BibTeX  |
|:--------|:--------:|:--------:|:--------:|:--------:|
| [Attention Is All You Need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) | NeurIPS'17 | -- | [GitHub](https://github.com/tensorflow/tensor2tensor) | <details> <summary>Bib</summary> <p align="left">  @inproceedings{vaswani2017attention, </br>   title={Attention is all you need}, </br>   author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia}, </br>  booktitle={Advances in neural information processing systems}, </br>  pages={5998--6008}, </br>   year={2017} </br> }  </p></details>

## Awesome vTransformer Libraies
- [WaitingToAdd](https://github.com/penghouwen/VisionTransformer/blob/main/README.md)

